{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pylab as plt\n",
    "import config as cf\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style()\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cf.round1_train_file_path, sep = ' ')\n",
    "test_df = pd.read_csv(cf.round1_test_file_path, sep = ' ')\n",
    "\n",
    "category_df = train_df['item_category_list'].unique()\n",
    "category_ids = pd.DataFrame({'item_category_list' : category_df, 'item_category_id' : np.arange(len(category_df))})\n",
    "train_df = train_df.merge(category_ids, on='item_category_list')\n",
    "test_df = test_df.merge(category_ids, on='item_category_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_to(proc_func, train_df, test_df):\n",
    "    tr_df = proc_func(train_df)\n",
    "    te_df = proc_func(test_df)\n",
    "    return tr_df, te_df\n",
    "\n",
    "def apply_to(proc_func, train_df, test_df, on=None):\n",
    "    a_df = proc_func(train_df)\n",
    "    if on:\n",
    "        tr_df = train_df[on].merge(a_df)\n",
    "        te_df = test_df[on].merge(a_df)\n",
    "    else:\n",
    "        tr_df = train_df.merge(a_df)\n",
    "        te_df = test_df.merge(a_df)\n",
    "    return tr_df.drop_duplicates(), te_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 建立基础特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_base_feature(df):\n",
    "    feature_list = []\n",
    "    if 'is_trade' in df:\n",
    "        feature_list.append('is_trade')\n",
    "    feature_list.extend(['instance_id', 'item_id', 'user_id', 'context_id', 'shop_id'])\n",
    "    feature_list.extend(['item_brand_id', 'item_city_id', 'item_category_id'])\n",
    "    feature_list.extend(['item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level',\n",
    "                         'user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level',\n",
    "                         'context_page_id', 'shop_review_num_level', 'shop_star_level',\n",
    "                         'shop_review_positive_rate', 'shop_score_service', 'shop_score_delivery', 'shop_score_description'])\n",
    "    return df[feature_list]\n",
    "\n",
    "def process_base_feature(train_df, test_df):\n",
    "    tr_df = gen_base_feature(train_df)\n",
    "    te_df = gen_base_feature(test_df)\n",
    "    return tr_df, te_df\n",
    "    \n",
    "# train_base_ft, test_base_ft = process_base_feature(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 建立用户特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_user_item_feature(df):\n",
    "    user_item_df = df[['user_id', 'item_id', 'item_brand_id', 'item_category_id', 'is_trade']]\n",
    "\n",
    "    # user trade rate.\n",
    "    # user trade rate, group by catetory.\n",
    "    user_rate = user_item_df[['user_id', 'is_trade']].rename(columns={'is_trade':'u_trade_cnt'})\n",
    "    user_rate.loc[:,'user_cnt'] = 1\n",
    "    user_rate = user_rate.groupby('user_id', as_index=False).sum()\n",
    "    #user_rate.sort_values(['u_trade_cnt', 'user_cnt'], ascending=[False,True])\n",
    "\n",
    "    user_item_rate = user_item_df[['user_id', 'item_id', 'is_trade']].rename(columns={'is_trade':'u_item_trade_cnt'})\n",
    "    user_item_rate.loc[:, 'u_item_cnt'] = 1\n",
    "    user_item_rate = user_item_rate.groupby(['user_id', 'item_id'], as_index=False).sum()\n",
    "    user_item_rate.loc[:, 'u_item_rate'] = user_item_rate['u_item_trade_cnt'] / user_item_rate['u_item_cnt']\n",
    "#     user_item_rate.sort_values(['u_item_trade_cnt', 'u_item_cnt'], ascending=[False,True])\n",
    "\n",
    "    user_brand_rate = user_item_df[['user_id', 'item_brand_id', 'is_trade']].rename(columns={'is_trade':'u_brand_trade_cnt'})\n",
    "    user_brand_rate.loc[:, 'u_brand_cnt'] = 1\n",
    "    user_brand_rate = user_brand_rate.groupby(['user_id', 'item_brand_id'], as_index=False).sum()\n",
    "    user_brand_rate.loc[:, 'u_brand_rate'] = user_brand_rate['u_brand_trade_cnt'] / user_brand_rate['u_brand_cnt']\n",
    "#     user_brand_rate.sort_values(['u_brand_trade_cnt', 'u_brand_cnt'], ascending=[False,True])\n",
    "\n",
    "    user_cate_rate = user_item_df[['user_id', 'item_category_id', 'is_trade']].rename(columns={'is_trade':'u_cate_trade_cnt'})\n",
    "    user_cate_rate.loc[:, 'u_cate_cnt'] = 1\n",
    "    user_cate_rate = user_cate_rate.groupby(['user_id', 'item_category_id'], as_index=False).sum()\n",
    "    user_cate_rate.loc[:, 'u_cate_rate'] = user_cate_rate['u_cate_trade_cnt'] / user_cate_rate['u_cate_cnt']\n",
    "#     user_cate_rate.sort_values(['u_cate_trade_cnt', 'u_cate_cnt'], ascending=[False,True])\n",
    "\n",
    "    user_features = user_item_df.drop(columns=['is_trade']).drop_duplicates().merge(user_rate).merge(user_item_rate).merge(user_brand_rate).merge(user_cate_rate)\n",
    "    return user_features\n",
    "\n",
    "def process_user_item_feature(train_df, test_df):\n",
    "    return apply_to(gen_user_item_feature, train_df, test_df, ['user_id', 'item_id', 'item_brand_id', 'item_category_id'])\n",
    "\n",
    "# train_user_ft, test_user_ft = process_user_item_feature(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 建立商品特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_item_feature(df):\n",
    "    item_df = df[['item_id', 'item_brand_id', 'item_category_id', 'item_city_id', 'is_trade']]\n",
    "    \n",
    "    item_rate = item_df[['item_id', 'is_trade']].rename(columns={'is_trade':'item_trade_cnt'})\n",
    "    item_rate.loc[:, 'item_cnt'] = 1\n",
    "    item_rate = item_rate.groupby('item_id', as_index=False).sum()\n",
    "    item_rate.loc[:, 'item_rate'] = item_rate['item_trade_cnt'] / item_rate['item_cnt']\n",
    "    \n",
    "    item_brand_rate = item_df[['item_brand_id', 'is_trade']].rename(columns={'is_trade':'brand_trade_cnt'})\n",
    "    item_brand_rate.loc[:, 'brand_cnt'] = 1\n",
    "    item_brand_rate = item_brand_rate.groupby('item_brand_id', as_index=False).sum()\n",
    "    item_brand_rate.loc[:, 'brand_rate'] = item_brand_rate['brand_trade_cnt'] / item_brand_rate['brand_cnt']\n",
    "    \n",
    "    item_cate_rate = item_df[['item_category_id', 'is_trade']].rename(columns={'is_trade':'cate_trade_cnt'})\n",
    "    item_cate_rate.loc[:, 'cate_cnt'] = 1\n",
    "    item_cate_rate = item_cate_rate.groupby('item_category_id', as_index=False).sum()\n",
    "    item_cate_rate.loc[:, 'cate_rate'] = item_cate_rate['cate_trade_cnt'] / item_cate_rate['cate_cnt']\n",
    "    \n",
    "    item_city_rate = item_df[['item_city_id', 'is_trade']].rename(columns={'is_trade':'city_trade_cnt'})\n",
    "    item_city_rate.loc[:, 'city_cnt'] = 1\n",
    "    item_city_rate = item_city_rate.groupby('item_city_id', as_index=False).sum()\n",
    "    item_city_rate.loc[:, 'city_rate'] = item_city_rate['city_trade_cnt'] / item_city_rate['city_cnt']\n",
    "    \n",
    "    feature_df = item_df.drop(columns=['is_trade']).drop_duplicates().merge(item_rate).merge(item_brand_rate).merge(item_cate_rate).merge(item_city_rate)\n",
    "    return feature_df\n",
    "\n",
    "def process_item_feature(train_df, test_df):\n",
    "    return apply_to(gen_item_feature, train_df, test_df, ['item_id', 'item_brand_id', 'item_category_id', 'item_city_id'])\n",
    "\n",
    "train_item_ft, test_item_ft = process_item_feature(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 建立上下文特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category_hit(row):\n",
    "    pre_list = row['predict_category_property'].split(';')\n",
    "    category_list = row['item_category_list'].split(';')\n",
    "    # start with second level category\n",
    "    ret = 0\n",
    "    for i in category_list[1:]:\n",
    "        for k in range(len(pre_list)):\n",
    "            if i in pre_list[k]:\n",
    "                # combime small datas.\n",
    "                if ret == 0 or k < ret:\n",
    "                    return 5 if k > 5 else k\n",
    "    return ret\n",
    "\n",
    "def gen_context_time_feature(df):\n",
    "    context_df = df[['context_id', 'context_timestamp', 'context_page_id']]\n",
    "    context_df.loc[:,'context_datetime'] = pd.to_datetime(context_df.loc[:,'context_timestamp'], unit='s')\n",
    "    # by day\n",
    "    # context_df.loc[:,'context_day'] = context_df.loc[:,'context_datetime'].map(lambda x:x.day)\n",
    "    # by hours\n",
    "    context_df.loc[:,'context_hour'] = context_df.loc[:,'context_datetime'].map(lambda x:x.hour)\n",
    "    \n",
    "    return context_df.drop(columns=['context_datetime'])\n",
    "\n",
    "def gen_context_predict_feature(df):\n",
    "    cp_df = df[['item_category_list', 'predict_category_property']]\n",
    "    frame = cp_df.apply(predict_category_hit, axis=1)\n",
    "    frame.name = 'category_predict_hit'\n",
    "    ret_df = df[['context_id']].join(frame)    \n",
    "    return ret_df\n",
    "\n",
    "def process_context_time_feature(train_df, test_df):\n",
    "    return cast_to(gen_context_time_feature, train_df, test_df)\n",
    "\n",
    "def process_context_predict_feature(train_df, test_df):\n",
    "    return cast_to(gen_context_predict_feature, train_df, test_df)\n",
    "\n",
    "# train_item_ct1, test_item_ct1 = process_context_time_feature(train_df, test_df)\n",
    "# train_item_ct2, test_item_ct2 = process_context_predict_feature(train_df, test_df)\n",
    "# TODO: 建立上下文预测属性数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 建立店铺特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_shop_feature(df):\n",
    "    shop_df = df[['shop_id', 'is_trade']]\n",
    "\n",
    "    # shop trade rate.\n",
    "    # shop trade rate, group by catetory.\n",
    "    shop_rate = shop_df[['shop_id', 'is_trade']].rename(columns={'is_trade':'s_trade_cnt'})\n",
    "    shop_rate.loc[:,'shop_cnt'] = 1\n",
    "    shop_rate = shop_rate.groupby('shop_id', as_index=False).sum()\n",
    "    #user_rate.sort_values(['u_trade_cnt', 'user_cnt'], ascending=[False,True])\n",
    "    \n",
    "    shop_feature = shop_df.merge(shop_rate)\n",
    "    return shop_feature.drop(columns=['is_trade']).drop_duplicates()\n",
    "    \n",
    "\n",
    "def process_shop_score_qcut_feature(train_df, test_df):\n",
    "    tr_shop_df = train_df[['shop_id', 'shop_review_positive_rate', 'shop_score_service', 'shop_score_delivery', 'shop_score_description']]\n",
    "    te_shop_df = test_df[['shop_id', 'shop_review_positive_rate', 'shop_score_service', 'shop_score_delivery', 'shop_score_description']]\n",
    "    \n",
    "    a_shop_df = tr_shop_df.append(te_shop_df)\n",
    "    labels = map(lambda x:str(x), range(11))\n",
    "    \n",
    "    _, bins = pd.qcut(a_shop_df['shop_review_positive_rate'], 24, retbins=True, duplicates='drop')\n",
    "    tr_shop_df.loc[:,'shop_review_positive_rate_qcut'] = pd.cut(tr_shop_df['shop_review_positive_rate'], bins=bins, labels=labels).astype(int)\n",
    "    te_shop_df.loc[:,'shop_review_positive_rate_qcut'] = pd.cut(te_shop_df['shop_review_positive_rate'], bins=bins, labels=labels).astype(int)\n",
    "    \n",
    "    _, bins = pd.qcut(a_shop_df['shop_score_service'], 11, retbins=True, duplicates='drop')\n",
    "    tr_shop_df.loc[:,'shop_score_service_qcut'] = pd.cut(tr_shop_df['shop_score_service'], bins=bins, labels=labels).astype(int)\n",
    "    te_shop_df.loc[:,'shop_score_service_qcut'] = pd.cut(te_shop_df['shop_score_service'], bins=bins, labels=labels).astype(int)\n",
    "    \n",
    "    _, bins = pd.qcut(a_shop_df['shop_score_delivery'], 11, retbins=True, duplicates='drop')\n",
    "    tr_shop_df.loc[:,'shop_score_delivery_qcut'] = pd.cut(tr_shop_df['shop_score_delivery'], bins=bins, labels=labels).astype(int)\n",
    "    te_shop_df.loc[:,'shop_score_delivery_qcut'] = pd.cut(te_shop_df['shop_score_delivery'], bins=bins, labels=labels).astype(int)\n",
    "    \n",
    "    _, bins = pd.qcut(a_shop_df['shop_score_description'], 11, retbins=True, duplicates='drop')\n",
    "    tr_shop_df.loc[:,'shop_score_description_qcut'] = pd.cut(tr_shop_df['shop_score_description'], bins=bins, labels=labels).astype(int)\n",
    "    te_shop_df.loc[:,'shop_score_description_qcut'] = pd.cut(te_shop_df['shop_score_description'], bins=bins, labels=labels).astype(int)\n",
    "    \n",
    "    return tr_shop_df.drop_duplicates(), te_shop_df.drop_duplicates()\n",
    "\n",
    "def process_shop_feature(train_df, test_df):\n",
    "    return apply_to(gen_shop_feature, train_df, test_df, ['shop_id'])\n",
    "\n",
    "# train_shop_ct1, test_shop_ct1 = process_shop_score_qcut_feature(train_df, test_df)\n",
    "# train_shop_ct2, test_shop_ct2 = process_shop_feature(train_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
