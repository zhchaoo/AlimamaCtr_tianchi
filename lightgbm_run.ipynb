{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pylab as plt\n",
    "import config as cf\n",
    "import import_ipynb\n",
    "import os\n",
    "import sys\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "from jupyterthemes import jtplot\n",
    "from IPython.core.display import clear_output\n",
    "from feature_extract import *\n",
    "\n",
    "jtplot.style()\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "os.mkdir('{0}_{1}'.format(cf.model_path, exec_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainV_df = pd.read_csv(cf.train_valid_features_file_path, index_col=0).reset_index()\n",
    "testV_df = pd.read_csv(cf.test_valid_features_file_path, index_col=0).reset_index()\n",
    "\n",
    "train_df = pd.read_csv(cf.train_data_features_file_path, index_col=0).reset_index()\n",
    "test_df = pd.read_csv(cf.test_data_features_file_path, index_col=0).reset_index()\n",
    "\n",
    "ret_test_df = pd.read_csv(cf.round1_test_file_path, sep=' ')\n",
    "\n",
    "# train_df.loc[:,'context_datetime'] = pd.to_datetime(train_df.loc[:,'context_timestamp'] + time_offset, unit='s')\n",
    "# train_df = train_df.loc[train_df['context_datetime'] < '2017-09-23']\n",
    "# train_df = train_df.drop(columns=['context_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print testV_df.shape\n",
    "print trainV_df.shape\n",
    "\n",
    "print test_df.shape\n",
    "print train_df.shape\n",
    "\n",
    "print trainV_df[['is_trade']].describe()\n",
    "print testV_df[['is_trade']].describe()\n",
    "print train_df[['is_trade']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_start = 7\n",
    "exclude_columns = ['user_is_id']\n",
    "exclude_columns = []\n",
    "\n",
    "trainV_y = trainV_df.iloc[:,1]\n",
    "trainV_X = trainV_df.iloc[:,feature_start + 1:].drop(columns=exclude_columns)\n",
    "testV_y = testV_df.iloc[:,1]\n",
    "testV_X = testV_df.iloc[:,feature_start + 1:].drop(columns=exclude_columns)\n",
    "\n",
    "train_y = train_df.iloc[:,1]\n",
    "train_X = train_df.iloc[:,feature_start + 1:].drop(columns=exclude_columns)\n",
    "test_X = test_df.iloc[:,feature_start:].drop(columns=exclude_columns)\n",
    "\n",
    "print trainV_X.shape\n",
    "print testV_X.shape\n",
    "print train_X.shape\n",
    "print test_X.shape\n",
    "print train_X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "lgb_args = {\n",
    "    'num_leaves': 72,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.05,\n",
    "    'seed': 42,\n",
    "    # 'min_child_samples' : 8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.9\n",
    "}\n",
    "\n",
    "early_stopping_rounds=200\n",
    "valid_n_estimators=5000\n",
    "best_iter=112\n",
    "categorical_feature=['user_gender_id', 'user_occupation_id', 'item_category_id',\n",
    "                     'price_sale', 'collect_sale', 'collect_price', 'gender_age', 'gender_occ', 'gender_star', 'review_star']\n",
    "# categorical_feature='auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "print('Training LGBM model...')\n",
    "clf = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=valid_n_estimators,\n",
    "    **lgb_args)\n",
    "\n",
    "save_stdout = sys.stdout\n",
    "with open('{0}_{1}/{2}'.format(cf.model_path, exec_time, cf.model_valid_log), 'w+') as outf:\n",
    "    sys.stdout = outf\n",
    "    lgb_model = clf.fit(trainV_X, trainV_y, eval_set=[(testV_X, testV_y)], early_stopping_rounds=early_stopping_rounds, categorical_feature=categorical_feature)\n",
    "    sys.stdout = save_stdout\n",
    "\n",
    "    best_iter = lgb_model.best_iteration_\n",
    "    pred_y = lgb_model.predict_proba(testV_X)[:, 1]\n",
    "    # print(test[['is_trade','pred']])\n",
    "    best_eval = log_loss(testV_y.values, pred_y)\n",
    "    outf.write(\"best %f:%s\" %(best_eval, {'n_estimators':best_iter}))\n",
    "    print \"best %f:%s\" %(best_eval, {'n_estimators':best_iter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pred\n",
    "clf = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    n_estimators=best_iter,\n",
    "    **lgb_args)\n",
    "\n",
    "# clf = lgb.LGBMClassifier(num_leaves=78, max_depth=9, n_estimators=100, n_jobs=20)\n",
    "clf.fit(train_X, train_y, categorical_feature=categorical_feature)\n",
    "test_pred = pd.Series(clf.predict_proba(test_X)[:,1])\n",
    "test_pred.name = 'predicted_score'\n",
    "\n",
    "test_pred.hist(bins=100)\n",
    "print test_pred.nunique()\n",
    "print test_pred.value_counts().head()\n",
    "\n",
    "pred_df = test_df[['instance_id']].join(test_pred)\n",
    "ret_df = ret_test_df[['instance_id']].merge(pred_df)\n",
    "\n",
    "print ret_df.describe()\n",
    "\n",
    "ret_df.to_csv('{0}_{1}/{1}_{2}'.format(cf.model_path, exec_time, cf.result_filename), sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#analysis\n",
    "imp_df = pd.DataFrame({'feature_name':train_X.columns.values, 'importance':clf.feature_importances_}).sort_values('importance', ascending=False)\n",
    "imp_df.to_csv('{0}_{1}/{1}_{2}'.format(cf.model_path, exec_time, 'importance.csv'), index=False)\n",
    "lgb.plot_importance(clf)\n",
    "imp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
