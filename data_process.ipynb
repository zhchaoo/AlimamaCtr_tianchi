{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pylab as plt\n",
    "import config as cf\n",
    "import import_ipynb\n",
    "import sys\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "from jupyterthemes import jtplot\n",
    "from IPython.core.display import clear_output\n",
    "from feature_extract import *\n",
    "\n",
    "jtplot.style()\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainV_df = train_df.loc[((train_df['context_datetime'] >= '2017-09-19') & (train_df['context_datetime'] < '2017-09-25')) | ((train_df['context_datetime'] < '2017-09-19') & (train_df['context_timestamp'] % 3 != 0))]\n",
    "# testV_df = train_df.loc[(train_df['context_datetime'] >= '2017-09-18') & (train_df['context_datetime'] < '2017-09-19') & (train_df['context_timestamp'] % 3 == 0)]\n",
    "\n",
    "trainV_df = train_df.loc[(train_df['context_datetime'] >= '2017-09-18') & (train_df['context_datetime'] < '2017-09-24')]\n",
    "testV_df = train_df.loc[(train_df['context_datetime'] >= '2017-09-24') & (train_df['context_datetime'] < '2017-09-25')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(train_df), len(test_df)\n",
    "print len(trainV_df), len(testV_df)\n",
    "\n",
    "a = set(train_df['user_id'].tolist())\n",
    "b = set(test_df['user_id'].tolist())\n",
    "print 'train user count : %d, test user count : %d, both user count : %d' %(len(a), len(b), len(a & b))\n",
    "a = set(trainV_df['user_id'].tolist())\n",
    "b = set(test_df['user_id'].tolist())\n",
    "print 'trainV user count : %d, test user count : %d, both user count : %d' %(len(a), len(b), len(a & b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 应用特征处理的结果到验证的训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test_features(tr_df, te_df, st_df, all_df, proc_func_list):\n",
    "    tr_fs, te_fs = process_base_feature(tr_df, te_df)\n",
    "\n",
    "    print 'begin base:', len(tr_fs), len(te_fs)\n",
    "    for proc_func in proc_func_list:\n",
    "        clear_output()\n",
    "        print 'processing ' + proc_func.func_name + ' ...'\n",
    "        tr_f, te_f = proc_func(tr_df, te_df, st_df, all_df)\n",
    "        clear_output()\n",
    "        print 'merging ' + proc_func.func_name + ':', len(tr_f), len(te_f)\n",
    "        tr_fs = tr_fs.merge(tr_f, how='left')\n",
    "        te_fs = te_fs.merge(te_f, how='left')\n",
    "    clear_output()\n",
    "    map(lambda x:x.drop_duplicates(inplace=True), (tr_fs, te_fs))\n",
    "    print 'done features:', len(tr_fs), len(te_fs)\n",
    "    return tr_fs, te_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast features\n",
    "fast_proc_func_list = [process_base_combine_feature, process_intersection_id,\n",
    "                       process_context_predict_feature, process_context_time_feature,\n",
    "                       process_user_ot_feature, process_user_item_ot_feature,\n",
    "                       process_item_ot_feature, process_shop_ot_feature,\n",
    "                       process_item_property_feature, process_shop_score_qcut_feature,\n",
    "                       process_item_prob_feature, process_user_prob_feature, process_user_item_prob_feature]\n",
    "\n",
    "trV_fs, teV_fs = process_train_test_features(trainV_df, testV_df, stat_df, all_df, fast_proc_func_list)\n",
    "tr_fs, te_fs = process_train_test_features(train_df, test_df, stat_df, all_df, fast_proc_func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow features\n",
    "user_old = True\n",
    "\n",
    "if user_old:\n",
    "    trV_fs_2 = pd.read_csv(cf.train_valid_features_2_file_path, index_col=0)\n",
    "    teV_fs_2 = pd.read_csv(cf.test_valid_features_2_file_path, index_col=0)\n",
    "    tr_fs_2 = pd.read_csv(cf.train_data_features_2_file_path, index_col=0)\n",
    "    te_fs_2 = pd.read_csv(cf.test_data_features_2_file_path, index_col=0)\n",
    "else:\n",
    "    slow_proc_func_list = [process_context_time_rolling_feature]\n",
    "    trV_fs_2, teV_fs_2 = process_train_test_features(trainV_df, testV_df, stat_df, all_df, slow_proc_func_list)\n",
    "    tr_fs_2, te_fs_2 = process_train_test_features(train_df, test_df, stat_df, all_df, slow_proc_func_list)\n",
    "    trV_fs_2.to_csv(cf.train_valid_features_2_file_path)\n",
    "    teV_fs_2.to_csv(cf.test_valid_features_2_file_path)\n",
    "    tr_fs_2.to_csv(cf.train_data_features_2_file_path)\n",
    "    te_fs_2.to_csv(cf.test_data_features_2_file_path)\n",
    "\n",
    "train_drop_columns = tr_fs_2.iloc[:,2:29].columns.values\n",
    "test_drop_columns = te_fs_2.iloc[:,1:28].columns.values\n",
    "trV_fs = trV_fs.merge(trV_fs_2.drop(columns=train_drop_columns), how='left')\n",
    "teV_fs = teV_fs.merge(teV_fs_2.drop(columns=test_drop_columns), how='left')\n",
    "tr_fs = tr_fs.merge(tr_fs_2.drop(columns=train_drop_columns), how='left')\n",
    "te_fs = te_fs.merge(te_fs_2.drop(columns=test_drop_columns), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print tr_fs.columns.values\n",
    "print tr_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trV_fs.to_csv(cf.train_valid_features_file_path)\n",
    "teV_fs.to_csv(cf.test_valid_features_file_path)\n",
    "\n",
    "tr_fs.to_csv(cf.train_data_features_file_path)\n",
    "te_fs.to_csv(cf.test_data_features_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
