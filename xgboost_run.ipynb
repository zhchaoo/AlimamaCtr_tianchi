{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pylab as plt\n",
    "import config as cf\n",
    "import import_ipynb\n",
    "import os\n",
    "import sys\n",
    "import xgboost\n",
    "import time\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "from chinese_calendar import is_workday, is_holiday\n",
    "from jupyterthemes import jtplot\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "jtplot.style()\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:96% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "os.mkdir('{0}_{1}'.format(cf.model_path, exec_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(cf.train_data_features_file_path, index_col=0).reset_index()\n",
    "test_df = pd.read_csv(cf.test_data_features_file_path, index_col=0).reset_index()\n",
    "test_a_df = pd.read_csv(cf.round1_test_a_file_path, sep = ' ')\n",
    "test_b_df = pd.read_csv(cf.round1_test_b_file_path, sep = ' ')\n",
    "\n",
    "trainV_df = train_df.loc[train_df['context_day'] != 24]\n",
    "testV_df = train_df.loc[train_df['context_day'] == 24]\n",
    "\n",
    "ret_test_df = test_b_df\n",
    "\n",
    "# train_df.loc[:,'context_datetime'] = pd.to_datetime(train_df.loc[:,'context_timestamp'] + time_offset, unit='s')\n",
    "# train_df = train_df.loc[train_df['context_datetime'] < '2017-09-23']\n",
    "# train_df = train_df.drop(columns=['context_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print testV_df.shape\n",
    "print trainV_df.shape\n",
    "\n",
    "print test_df.shape\n",
    "print train_df.shape\n",
    "\n",
    "print trainV_df[['is_trade']].describe()\n",
    "print testV_df[['is_trade']].describe()\n",
    "print train_df[['is_trade']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_start = 10 \n",
    "feature_start = 6\n",
    "exclude_columns = []\n",
    "# exclude_columns = ['user_id_is', 'item_id_is', 'shop_id_is', 'item_brand_id_is']\n",
    "# exclude_columns.extend(filter(lambda x:x.startswith('ui'), train_df.columns.values))\n",
    "# exclude_columns.extend(filter(lambda x:x.endswith('user_cnt'), train_df.columns.values))\n",
    "\n",
    "trainV_y = trainV_df.iloc[:,1]\n",
    "trainV_X = trainV_df.iloc[:,feature_start + 1:].drop(columns=exclude_columns)\n",
    "testV_y = testV_df.iloc[:,1]\n",
    "testV_X = testV_df.iloc[:,feature_start + 1:].drop(columns=exclude_columns)\n",
    "\n",
    "train_y = train_df.iloc[:,1]\n",
    "train_X = train_df.iloc[:,feature_start + 1:].drop(columns=exclude_columns)\n",
    "test_X = test_df.iloc[:,feature_start:].drop(columns=exclude_columns)\n",
    "\n",
    "print trainV_X.shape\n",
    "print testV_X.shape\n",
    "print train_X.shape\n",
    "print test_X.shape\n",
    "print train_X.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "trainV_matrix = xgboost.DMatrix(trainV_X.values, label=trainV_y.values, feature_names=trainV_X.columns)\n",
    "testV_matrix = xgboost.DMatrix(testV_X.values, label=testV_y.values, feature_names=testV_X.columns)\n",
    "\n",
    "train_matrix = xgboost.DMatrix(train_X.values, label=train_y.values, feature_names=train_X.columns)\n",
    "predict_matrix = xgboost.DMatrix(test_X.values, feature_names=test_X.columns)\n",
    "\n",
    "watchlist = [(trainV_matrix, 'train'), (testV_matrix, 'eval')]\n",
    "num_round=5000\n",
    "early_stopping_rounds=200\n",
    "param = {\n",
    "    'max_depth': 8,\n",
    "    'eta': 0.05,\n",
    "    'silent': 1,\n",
    "    'seed': 42,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "#     'scale_pos_weight': 2,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "#     'min_child_weight': 100,\n",
    "#     'max_delta_step': 20\n",
    "}\n",
    "\n",
    "\n",
    "print 'model training'\n",
    "save_stdout = sys.stdout\n",
    "with open('{0}_{1}/{2}'.format(cf.model_path, exec_time, cf.model_valid_log), 'w+') as outf:\n",
    "#     sys.stdout = outf\n",
    "    model = xgboost.train(param, trainV_matrix, num_boost_round=num_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds)\n",
    "    # test\n",
    "    test_matrix = xgboost.DMatrix(testV_X.values, feature_names=testV_X.columns)\n",
    "\n",
    "    pred_y = model.predict(test_matrix, ntree_limit=model.best_ntree_limit)\n",
    "    frame = pd.Series(pred_y, index=testV_df.index)\n",
    "    frame.name = 'predicted_score'\n",
    "    best_eval = log_loss(testV_y.values, pred_y)\n",
    "    outf.write(\"best %f:%s\" %(best_eval, {'n_estimators':model.best_iteration}))\n",
    "    \n",
    "frame.hist(bins=100)\n",
    "print frame.value_counts().head()\n",
    "print frame.describe()\n",
    "print \"test log loss:\", best_eval\n",
    "# sys.stdout = save_stdout\n",
    "print 'model.best_score: {0}, model.best_iteration: {1}, model.best_ntree_limit: {2}'.format(model.best_score, model.best_iteration, model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "pred_y = model.predict(predict_matrix, ntree_limit=model.best_ntree_limit)\n",
    "frame = pd.Series(pred_y, index=test_df.index)\n",
    "frame.name = 'predicted_score'\n",
    "frame.hist(bins=100)\n",
    "print frame.value_counts().head()\n",
    "\n",
    "pred_df = test_df[['instance_id']].join(frame)\n",
    "ret_df = ret_test_df[['instance_id']].merge(pred_df)\n",
    "\n",
    "print ret_df.describe()\n",
    "\n",
    "ret_df.to_csv('{0}_{1}/{1}_{2}'.format(cf.model_path, exec_time, cf.result_filename), sep=' ', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis\n",
    "xgboost.plot_importance(model)\n",
    "imp_df = pd.DataFrame(model.get_fscore().items(), columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "imp_df.to_csv('{0}_{1}/{1}_{2}'.format(cf.model_path, exec_time, 'importance.csv'), index=False)\n",
    "imp_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
